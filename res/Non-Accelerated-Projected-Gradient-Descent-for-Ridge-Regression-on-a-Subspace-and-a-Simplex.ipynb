{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7834187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba34a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.randn(3) \n",
    "K = np.random.randn(3, 7)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef42bea",
   "metadata": {},
   "source": [
    "### Ridge Regression and its gradient descent version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463af5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07510553 -0.11696049  0.09250367  0.04916155  0.08432023 -0.08204641\n",
      " -0.04978814]\n",
      "10 0.21308928631528687\n",
      "20 0.00028595379934584584\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "ridge = sklearn.linear_model.Ridge(alpha = alpha, fit_intercept=False, random_state=123).fit(K, q)\n",
    "true_coef = ridge.coef_\n",
    "v1 = np.linalg.inv(K.T @ K + alpha * np.eye(7)) @ (K.T @ q)\n",
    "np.testing.assert_allclose(true_coef, v1)\n",
    "print(v1)\n",
    "a = np.zeros(7)\n",
    "L = 20\n",
    "alpha_max = 3 * alpha\n",
    "for l in range(1, L + 1):\n",
    "    kappa = (alpha_max * (alpha/alpha_max) ** (l/L))/(K.shape[0] * K.shape[1])\n",
    "    a = a - kappa * (K.T @ (K @ a - q) + alpha * a)\n",
    "    if l % 10 == 0:\n",
    "        print(l, np.linalg.norm(a - v1) / np.linalg.norm(a))\n",
    "        # print(a - v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961135fb",
   "metadata": {},
   "source": [
    "### Subspace Ridge Regression and its Projected Gradient Descent Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351c5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt as opt\n",
    "from cvxopt import matrix\n",
    "from cvxopt.solvers import qp, options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7666d",
   "metadata": {},
   "source": [
    "Test in the simpler case of pure regression without constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4cfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_q = matrix(-K.T @ q)\n",
    "cv_KK = matrix((K.T @ K + alpha * np.eye(7)))\n",
    "sol = qp(cv_KK, cv_q)['x']\n",
    "sol = np.array(sol).squeeze()\n",
    "np.testing.assert_allclose(sol, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd3dab",
   "metadata": {},
   "source": [
    "Now add the constraints, we can see that the solution is different from the unconstrained version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5981a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38176057 -0.08386346  0.04471772  0.29143839  0.18621987  0.01596309\n",
      "  0.16376384]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "A = matrix(np.ones(7)).T\n",
    "b = matrix(1.0)\n",
    "sol = qp(cv_KK, cv_q, A=A, b=b)['x']\n",
    "sol = np.array(sol).squeeze()\n",
    "\n",
    "print(sol)\n",
    "print(sol.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf9e42",
   "metadata": {},
   "source": [
    "Now execute projected gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbae9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.037875758408875665\n",
      "20 0.0091313500853822\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(7)\n",
    "L = 20\n",
    "alpha_max = 3 * alpha\n",
    "\n",
    "def proj_subspace(x):\n",
    "    return x - (x.sum() - 1) / 7\n",
    "\n",
    "for l in range(1, L + 1):\n",
    "    kappa = (alpha_max * (alpha/alpha_max) ** (l/L))/(K.shape[0] * K.shape[1])\n",
    "    a = proj_subspace(a - kappa * (K.T @ (K @ a - q) + alpha * a))\n",
    "    if l % 10 == 0:\n",
    "        print(l, np.linalg.norm(a - sol) / np.linalg.norm(sol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550af66",
   "metadata": {},
   "source": [
    "### Simplex Ridge Regression and its Projected Gradient Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953cded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.4000e-02 -1.1747e+00  1e+01  3e+00  1e+00\n",
      " 1: -7.0947e-02 -8.2415e-01  1e+00  8e-02  4e-02\n",
      " 2: -7.3828e-02 -1.5993e-01  9e-02  6e-03  3e-03\n",
      " 3: -8.5123e-02 -9.1853e-02  7e-03  1e-04  7e-05\n",
      " 4: -8.7191e-02 -8.7670e-02  5e-04  3e-06  2e-06\n",
      " 5: -8.7293e-02 -8.7312e-02  2e-05  3e-08  1e-08\n",
      " 6: -8.7294e-02 -8.7294e-02  2e-07  3e-10  1e-10\n",
      " 7: -8.7294e-02 -8.7294e-02  2e-09  3e-12  1e-12\n",
      "Optimal solution found.\n",
      "[4.24078454e-01 6.65517269e-11 2.35483901e-02 3.05264533e-01\n",
      " 1.36881333e-01 1.38425925e-10 1.10227291e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "G = matrix(- np.eye(7))\n",
    "h = matrix(np.zeros(7))\n",
    "sol = qp(cv_KK, cv_q, G=G, h=h, A=A, b=b)['x']\n",
    "sol = np.array(sol).squeeze()\n",
    "print(sol)\n",
    "print(sol.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76618585",
   "metadata": {},
   "source": [
    "Based on https://gist.github.com/mblondel/6f3b7aaad90606b98f71 which provides two other methods for projecting onto the simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3296887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.028416697153768034\n",
      "20 0.005185129304881217\n"
     ]
    }
   ],
   "source": [
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w\n",
    "\n",
    "\n",
    "a = np.zeros(7)\n",
    "L = 20\n",
    "alpha_max = 3 * alpha\n",
    "\n",
    "for l in range(1, L + 1):\n",
    "    kappa = (alpha_max * (alpha/alpha_max) ** (l/L))/(K.shape[0] * K.shape[1])\n",
    "    a = projection_simplex_sort(a - kappa * (K.T @ (K @ a - q) + alpha * a))\n",
    "    if l % 10 == 0:\n",
    "        print(l, np.linalg.norm(a - sol) / np.linalg.norm(sol))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
