<!DOCTYPE html>
<html>
<head>
      <meta charset="UTF-8" />
      <title>Pushpendre Rastogi Homepage</title>
      <style>
      * {
        box-sizing: border-box;
      }
      tr.spaceUnder>td {
            padding-bottom: 1em;
      }
      .column {
            float: left;
            padding: 10px;
      }
      .left {
            width: 20%;
      }
      .right {
            width: 80%;
      }
      /* Clear floats after the columns */
      .row:after {
            content: "";
            display: table;
            clear: both;
      }
      .menu {
            float:left;
            width:220px;
      }
      .mainContent {
            float:left;
            width:75%;
      }
      </style>
      <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/default.min.css">
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>
      <!-- /res/mathjax-es5-v3-2-2/tex-mml-svg.js -->
      <script src="/res/mathjax-es5-v3-2-2/tex-mml-chtml.js" type="text/javascript" charset="utf-8"></script>

</head>

<body>
<div class="row">
<div class="column left">
      <img src="res/header.png" width="90%" alt="header png"/>
      <a class="twitter-timeline"
         data-height="725"
         data-dnt="true" href="https://twitter.com/Pushpendre89?ref_src=twsrc%5Etfw">Twitter</a>
      <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
      <h4>Links</h4>
            <p><a href="https://stackexchange.com/users/257045/pushpendre">
                  <img src="https://stackexchange.com/users/flair/257045.png"
                       width="208" height="58"
                       alt="profile for Pushpendre on Stack Exchange"
                       title="profile for Pushpendre on Stack Exchange" />
                  </a>
            </p>
            <p><a href="https://github.com/se4u">github</a></p>
            <p><a href="https://www.linkedin.com/in/pushpendre/" >
                  <img src="https://upload.wikimedia.org/wikipedia/commons/0/01/LinkedIn_Logo.svg" width="100" height="25" alt="Linkedin Logo">
               </a>
            </p>
            <p><a href="https://github.com/pushpendre/pushpendre.github.io/blob/master/index.html">Edit this page</a></p>
            <p><a href="https://github.com/pushpendre/pushpendre.github.io/deployments/activity_log?environment=github-pages">See deployment status</a></p>
	    <details><summary>how to edit this page</summary>
            <p>make changes to index.html and validate them using "tidy --version ; tidy --warn-proprietary-attributes no -e -q index.html",
                this command is also added as a pre-commit hook. Also use "python -m http.server" to check that the site looks okay. For writing raw html go to <a href="res/editor.html">editor.html</a></p>
        </details>
</div>

<div class="column right">
<header class="col-span">
      <h1 class="title counter-skip">Pushpendre Rastogi</h1>
      <h2 class="subtitle counter-skip">pushpendre at gmail</h2>
</header>
<h2>Introduction</h2><p>I joined Amazon Prime Research to work on Plan Recommendation and Content Optimization in April 2020. I joined the Dialog State Tracking in Amazon Alexa in April 2019. I completed my Ph.D. in Computer Science at <a href="http://www.clsp.jhu.edu">The Center For Language and Speech Processing, Johns Hopkins University</a>. My advisor was <a href="http://www.cs.jhu.edu/~vandurme/">Benjamin Van Durme</a>. I TA'd graduate courses on representation learning and machine learning for three semesters during my Phd studies, and I received the <a href="https://engineering.jhu.edu/excellence-teaching-awards/#tbs_nav_item_1">George Sommerman Graduate Teaching Assistant Award</a> with a cash award of $1000. I have reviewed for Transactions On Signal Processing-19, NEURIPS-19, ICML-19, ICLR-19, EMNLP-19, ACL-19, TPAMI-18, NeurIPS-18, KG4IR-18, EMNLP-18, ACL-18.</p>
<h2>Selected Publications</h2>
<p>See my <a href="https://scholar.google.com/citations?user=nqDASHMAAAAJ">google scholar profile</a> for a complete list of publications.</p>
      <ul>
            <li>"Improving long distance slot carryover in spoken dialog systems".<a href="http://www.cs.jhu.edu/~tongfei/">Tongfei Chen</a>, Chetan Naik, Hua He, Pushpendre Rastogi, and Lambert Mathias. (2019) <a href="https://arxiv.org/abs/1906.01149">[arxiv]</a> <a style="background-color: rgb(255,255,0); color: rgb(255,0,0)" href="https://sites.google.com/view/nlp4convai/program">[bestpaper]</a></li>
            <li>"Scaling Multi-Domain Dialogue State Tracking via Query Reformulation".Pushpendre Rastogi, <a href="https://www.linkedin.com/in/arpit-gupta-77759719/">Arpit Gupta</a>, <a href="http://www.cs.jhu.edu/~tongfei/">Tongfei Chen</a>, and Lambert Mathias. (2019) <a href="https://arxiv.org/abs/1903.05164">[arxiv]</a> <a href="http://www.xuwei.io/2019/03/25/%E3%80%8Ascaling-multi-domain-dialogue-state-tracking-via-query-reformulation%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0">[chinese-translation-1]</a> <a href="https://www.facebook.com/pushpendre/posts/2555616624460105">[chinese-translation-2]</a> <a href="https://github.com/alexa/alexa-dataset-contextual-query-rewrite">[dataset]</a>
<!-- style="background-color: rgb(255,255,0); color: rgb(255,0,0)" -->
<a href="https://venturebeat.com/2019/06/06/amazons-ai-rewrites-voice-commands-in-natural-language-to-reduce-false-positives">[press-venturebeat]</a></li>
            <li>"A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (cqr)".Michael Regan, Pushpendre Rastogi, <a href="https://www.linkedin.com/in/arpit-gupta-77759719/">Arpit Gupta</a>, and Lambert Mathias. (2019) <a href="https://arxiv.org/1903.11783">[arxiv]</a> <a href="https://github.com/alexa/alexa-dataset-contextual-query-rewrite">[dataset]</a></li>
            <li>"Neural variational entity set expansion for automatically populated knowledge graphs".Pushpendre Rastogi, <a href="https://www.cs.jhu.edu/~apoliak1/">Adam Poliak</a>, <a href="https://www.ams.jhu.edu/~lyzinski/">Vince Lyzinski</a>, and <a href="http://www.cs.jhu.edu/~vandurme/">Benjamin Van Durme</a>. (2018) <a href="/res/nvse.bib">[bib]</a> <a href="https://doi.org/10.1007/s10791-018-9342-1">[doi]</a> <a href="https://github.com/se4u/nvse">[code]</a> <a href="https://youtu.be/sGO_wvuPIzM">[demo]</a><a href="https://github.com/se4u/nvse/blob/master/kg4ir_journal_tex/kg4irjournal.pdf">[pdf]</a></li>
            <li>"Efficient, compositional, order-sensitive n-gram embeddings".<a href="https://www.cs.jhu.edu/~apoliak1/">Adam Poliak</a>, Pushpendre Rastogi, M. Patrick Martin, and <a href="http://www.cs.jhu.edu/~vandurme/">Benjamin Van Durme</a>. (2017) <a href="http://www.aclweb.org/anthology/E17-2081">[pdf]</a> <a href="http://www.aclweb.org/anthology/E17-2081.bib">[bib]</a> <a href="https://github.com/azpoliak/eco">[code]</a> <a href="https://www.cs.jhu.edu/~apoliak1/files/posters/ECO--EACL-2017-poster.pdf">[poster]</a></li>
            <li>"Vertex nomination on the cold start knowledge graph".Pushpendre Rastogi, <a href="https://www.ams.jhu.edu/~lyzinski/">Vince Lyzinski</a>, and <a href="http://www.cs.jhu.edu/~vandurme/">Benjamin Van Durme</a>. (2017) <a href="/res/kbvntr.pdf">[pdf]</a> <a href="/res/kbvntr.bib">[bib]</a></li>
            <li>"Weighting finite-state transductions with neural context".Pushpendre Rastogi, <a href="https://ryancotterell.github.io/">Ryan Cotterell</a>, and <a href="http://www.cs.jhu.edu/~jason/">Jason Eisner</a>. (2016) <a href="http://www.aclweb.org/anthology/N16-1076.bib">[bib]</a> <a href="http://www.aclweb.org/anthology/N16-1076">[pdf]</a> <a href="/res/rastogi2016weighting.slides.pdf">[slides]</a> <a href="https://github.com/se4u/neural_wfst.git">[code]</a></li>
            <li>"Efficient implementation of enhanced adaptive simultaneous perturbation algorithms".Pushpendre Rastogi, <a href="https://www.linkedin.com/in/jingyizhu/">Jingyi Zhu</a>, and <a href="http://www.ams.jhu.edu/~spall/Personal/">James Spall</a>. (2016) <a href="/res/rastogi2016efficient.bib">[bib]</a> <a href="https://github.com/se4u/FASPSA">[code]</a> <a href="/res/rastogi2016efficient.pdf">[pdf]</a> <a href="https://github.com/facebookresearch/nevergrad/pull/16">[nevergrad]</a></li>
            <li>"Multiview lsa: Representation learning via generalized cca".Pushpendre Rastogi, <a href="http://www.cs.jhu.edu/~vandurme/">Benjamin Van Durme</a>, and <a href="http://www.cs.jhu.edu/~raman/">Raman Arora</a>. (2015) <a href="http://www.aclweb.org/anthology/N15-1058">[pdf]</a> <a href="https://zenodo.org/record/16710">[data]</a> <a href="https://github.com/se4u/mvlsa">[code]</a> <a href="http://www.aclweb.org/anthology/N15-1058.bib">[bib]</a> <a href="/mvlsa/mvlsa_poster.pdf">[poster]</a> <a href="/mvlsa/multiview-lsa-proofs-and-faq.html">[supplementary]</a></li>
            <li>"Stationarity condition for fractional sampling filters".Pushpendre Rastogi. (2011) <a href="/res/mtp.pdf">[pdf]</a></li></ul>
<h2>Education</h2><table><tbody>
<tr><td style="text-align: left;"><a href="https://courses.edx.org/certificates/ce8af62f77ac47849920055856b1b15c">Introduction to Biology</a></td><td>MITx at EDX</td><td>2021</td><td>Pass</td></tr>
<tr><td style="text-align: left;">Ph.D. and M.S. in Computer Science</td><td>Johns Hopkins University</td><td>2013-19</td><td>3.75/4.0</td></tr>
<tr><td colspan="4" style="text-align: left;">Thesis Topic: Representation Learning for Words and Entities. I presented new methods for unsupervised learning of word and entity embeddings from texts and knowledge bases.<br />Courses and Grades: Natural Language Processing (A), Machine Learning in Complex Domains (A), Stochastic Search &amp; Optimization (B), Parallel Programming (A-), Principles of Programming Languages (A-), Combinatorial Optimization (A+), Introduction to Convexity (A-)</td></tr>
<tr><td style="text-align: left;">M.Tech. in Information and Communication Technology</td><td>IIT Delhi</td><td>2010-11</td><td>8.77/10</td></tr>
<tr><td style="text-align: left;">B.Tech. in Electrical Engg.</td><td>IIT Delhi</td><td>2006-10</td><td>8.86/10</td></tr>
</tbody></table>

<h2>Code Snippets</h2>
<!--  <details>
            <summary> XXX </summary>
            <p><pre><code> YYYY </code></pre>
</details> -->
<details>
            <summary> Bayesian Optimization in AX with constraints </summary>
            <p><pre class="language-python"><code>
"""
Based on
1. https://ax.dev/tutorials/tune_cnn.html
2. https://ax.dev/docs/api.html
3. https://ax.dev/tutorials/gpei_hartmann_service.html
4. https://ax.dev/tutorials/gpei_hartmann_loop.html
"""
from random import random
from ax.service.ax_client import AxClient


def f_to_minimize(w1, w2, w3):
    w4 = 1 - (w1 + w2 + w3)
    return (0.5 - w1)**2 + 1.2 *  (w2 - w1**2)**2 + (1.5 - w3)**2 + 3.2 *  (w4 - w3**2)**2 + (random() - 0.5) * 0.1

ax_client = AxClient()
ax_client.create_experiment(
    name="ax_experiment",
    parameters=[
        {
            "name": "w1",
            "type": "range",
            "bounds": [0.0, 1.0],
            "value_type": "float",
        },
        {
            "name": "w2",
            "type": "range",
            "bounds": [0.0, 1.0],
            "value_type": "float",
        },
        {
            "name": "w3",
            "type": "range",
            "bounds": [0.0, 1.0],
            "value_type": "float",
        },
    ],
    parameter_constraints=["w1 + w2 + w3 <= 1.0"],
    objective_name="f_to_minimize",
    minimize=True,
)

for _ in range(25):
    parameters, trial_index = ax_client.get_next_trial()
    ax_client.complete_trial(
        trial_index=trial_index,
        raw_data=f_to_minimize(parameters["w1"], parameters["w2"], parameters["w3"]))

best_parameters, metrics = ax_client.get_best_parameters()
</code></pre>
</details>
      <details>
            <summary> Simplify a jupyter notebook </summary>
            <p><pre class="language-python"><code>import json
j = json.load(open('input.ipynb'))

to_del = []
for ic, c in enumerate(j["cells"]):
    if c["cell_type"] == "code":
        for io, o in enumerate(c["outputs"]):
            if o["output_type"] == "stream" and o["name"] == "stderr":
                to_del.append((ic, io))

for ic, io in sorted(to_del, reverse=True):
    del j["cells"][ic]["outputs"][io]

with open('simplified.ipynb', 'w') as f:
    json.dump(j, f)</code></pre>
<p>&nbsp;</p></pre>
      </details>
      <details>
            <summary> Easily update configuration in a long running python process. </summary>
            <pre><code> """
CLI USAGE:
python listener.py l
python listener.py c foo bar
"""

from multiprocessing.managers import SyncManager
from time import sleep
import sys

__config__ = {}

def get_config():
    return __config__

def listener(address='/tmp/p2', authkey=b'password'):
    SyncManager.register("get_config", get_config)
    manager = SyncManager(address, authkey=authkey)
    manager.start()
    config = manager.get_config()
    return manager, config

def controller(address='/tmp/p2', authkey=b'password'):
    SyncManager.register("get_config")
    manager = SyncManager(address, authkey=authkey)
    manager.connect()
    config = manager.get_config()
    return config


if __name__ == '__main__':
    if sys.argv[1] == 'l':
        # from remote_control import listener
        manager, config = listener()
        while True:
            sleep(5)
            print(config)
        manager.shutdown()
    else:
        # from remote_control import controller
        config = controller()
        config.update([(sys.argv[2], sys.argv[3])])
 </code></pre>
      </details>
      <details>
            <summary> Interactive pool for running jobs on the side in python. </summary>
            <pre><code> class InteractivePool:
    def __init__(self, J):
        import time
        self.J = J
        self.tic = time.time()

    def done(self):
        return sum(1 for j in self.J if j.done()), len(self.J)

    def collect(self,R=None):
        R = R or {}
        print(len(R))
        for i, j in enumerate(self.J):
            if i not in R and j.done() and not j.cancelled():
                R[i] = j.result()
        print(len(R))
        return R

    def time(self):
        import datetime, time as time_module
        return str(datetime.timedelta(seconds=time_module.time() - self.tic))

    def wait(self, interval=600):
        import time
        while True:
            time.sleep(interval)
            if sum(1 for j in self.J if j.done()) == len(self.J):
                break
        return

from concurrent.futures import ProcessPoolExecutor
sidejob = ProcessPoolExecutor(max_workers=4).submit
P = InteractivePool([sidejob(f, i) for i in range(80)]) </code></pre>
</details>

<details>
      <summary> Save spark dataframe to sparse scipy arrays </summary>
      <pre><code> from functools import partial
import pyspark.ml as pm
from typing import *
from scipy.sparse import csr_matrix, vstack, lil_matrix, load_npz, save_npz
from pyspark import TaskContext
from tempfile import TemporaryDirectory
from glob import glob

def sparseVectorList_to_CSRMatrix(X: List[pm.linalg.SparseVector]) -> csr_matrix:
     """ Convert list of pyspark sparse vectors to a scipy CSR matrix that
     a standard sklearn function/lightgbm can consume.
     """
     M = lil_matrix((len(X), X[0].size), dtype=np.float)
     for i, x in enumerate(X):
         I = np.argsort(x.indices)
         M.rows[i] = x.indices[I]
         M.data[i] = x.values[I]
     return M.tocsr(copy=False)

 class RowToPredict(NamedTuple):
     "This class was created just to facilitate linting and type hinting."
     customer_id: str
     features: pm.linalg.SparseVector

def save_features_in_spark_as_sparsescipy_to_hdfs(
     hdfs_dir,
     row_gen: Iterable[RowToPredict]):
     C, Flist = [], []
     for e in row_gen:
         Flist.append(e.features)
         C.append(e.customer_id)
     F = sparseVectorList_to_CSRMatrix(Flist)
     pid = TaskContext().partitionId()
     # Ideally I will upload file directly to HDFS, but I don't know how to directly
     # write to HDFS. hdfscli didn't work for me. So work-around is to save to local
     # file on task node, then upload to HDFS with a subprocess call.
     with TemporaryDirectory() as tmpdirname:
         print('created temporary directory', tmpdirname)
         fname = f'{tmpdirname}/F.{pid}.npz'
         cname = f'{tmpdirname}/C.{pid}.pkl'
         with open(fname) as fh:
             save_npz(fh, F)
         with open(cname) as fh:
             pickle.dump(C, fh)
         subprocess.getstatusoutput('hadoop fs -put {fname} {cname} {hdfs_dir}')
     return

# make sure that each partition has a reasonable number of rows so that we don't OOM.
npart = sdf.count() // 10000
sdf.rdd.repartition(npart).foreachPartition(partial(
    save_features_in_spark_as_sparsescipy_to_hdfs, '/data/')

# After saving all the parts to hdfs, download the parts, and open them on master node.
subprocess.getstatusoutput('hadoop -copyToLocal /data/ /home/hadoop/')
L = glob('data/*.npz')
F = vstack([load_npz(e) for e in L])
C = [c for e in L for c in pickle.load(open(e))] </code></pre>
</details>

<details>
      <summary> How to hash check pip files </summary>
      <pre><code> 1. Install virtualenv
1. Create workspace, download package.
1. Go where the requirements file is.
1. Create fresh empty environment and activate it
1. install all requirements
1. generate hashes for all installed packages
1. close the shell and create new one
1. Create fresh empty environment and activate it
1. check that the new requirements file can be installed with

pip install virtualenv  pip-tools
python3 -m venv env;  source env/bin/activate
 pip list > before; pip install -r requirements.txt; pip list > after
 pip-compile requirements.txt --generate-hashes # this overwrites the original file.
 exit; bash
 python3 -m venv env2; source env2/bin/activate
 pip install --require-hashes -r requirements.txt
</code></pre>
</details>

<details>
      <summary> hdfs file system functionality exposed to python </summary>
      <pre><code> def hdfs_exists(path, flag='-e'):
    code, output = subprocess.getstatusoutput(f'hadoop fs -test {flag} {path}')
    if code != 0:
        print(output)
        return False
    else:
        return True

def copyFromLocal(src, dst):
    return subprocess.getstatusoutput(f'hadoop fs -copyFromLocal {src} {dst}')

def copyToLocal(src, dst):
    return subprocess.getstatusoutput(f'hadoop fs -copyToLocal {src} {dst}') </code></pre>
</details>

<details>
      <summary> Spark Setup </summary>
      <pre><code> def setup(RUNDATE='2020-07-16', spark_setting_file=None):
    """ Construct spark session, setup logger, and read YAML files
    from prime-ml-repo in production EMR clusters. After reading yaml files
    format the paths with dates.

    RUNDATE is a date string like this '2020-05-30'
    """
    assert re.match('\d{4}-\d{2}-\d{2}', RUNDATE)
    if spark_setting_file is None:
        spark_setting_file = StringIO("""scoring:
     spark.executor.memory: '20G'
     spark.executor.memoryOverhead: '4G'
     spark.executor.cores: 4
     spark.task.cpus: 1
     spark.yarn.am.memory: '2G'
     spark.serializer: 'org.apache.spark.serializer.KryoSerializer'
     spark.driver.maxResultSize: 0
     spark.executor.extraJavaOptions: '-XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps'
     spark.kryoserializer.buffer.max: '512M'
     spark.cleaner.periodicGC.interval: '5min'
     spark.network.timeout: '600s'""")
    # Use logger to log everything to file and also to stderr.
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
    )
    fh = logging.FileHandler("/home/hadoop/scoring_log_file.log")
    fh.setLevel(logging.INFO)
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    logger.info(f"Initialize job parameters. {RUNDATE}")

    parameters = {}

    logger.info("Initialize spark settings and spark session.")
    spark = SparkSession.builder.appName("claire")
    for key, value in yaml.safe_load(spark_setting_file)["scoring"].items():
        logger.info(f'spark: {key}={value}')
        spark = spark.config(key, value)
    spark = spark.enableHiveSupport().getOrCreate()
    spark.sparkContext.setLogLevel(os.environ.get("SPARK_LOG_LEVEL", "DEBUG"))
    try:
        spark.sparkContext.setCheckpointDir("hdfs:///checkpoint/spark/")
    except Exception as exception:
        warnings.warn("Unable to set spark checkpoint directory !")
    return spark, parameters, logger </code></pre>
</details>

<details>
      <summary> Common model inspections on binary classification test set</summary>
      <pre><code> def tabulate(label, proba, **kwargs):
    """ Compute common statistics on a binary classification problem
    given the true labels and the class probabilities.
    """
    assert proba.shape[1] == 2
    assert len(label) == len(proba)
    R = SimpleNamespace()
    R.accuracy = (label == proba.argmax(1)).mean()
    R.majority_rule_accuracy = max(1 - label.mean(), label.mean())
    R.log_loss = -np.log(np.select([label==0, label==1],
                                   [proba[:, 0], proba[:, 1]])).mean()
    fpr, tpr, thresholds = skm.roc_curve(label, proba[:, 1])
    R.roc_auc = skm.auc(fpr, tpr)
    try:
        idx = np.where(fpr < 0.05)[0].max()
        R.tp_at_fp_less_than_5_percent = tpr[idx]
        R.fp_at_fp_less_than_5_percent = fpr[idx]
        R.threshold_at_fp_less_than_5_percent = thresholds[idx]
    except ValueError as e:
        print(e)
        pass
    precision, recall, thresholds = skm.precision_recall_curve(label, proba[:, 1])
    R.prauc = skm.auc(recall, precision)
    R.precision = precision
    R.recall = recall
    R.thresholds = thresholds
    idx = np.where(precision > 0.9)[0].min()
    R.smallest_precision_greater_than_90pct = precision[idx]
    R.recall_at_precision_90pct = recall[idx]
    R.threshold_at_precision_90pct = thresholds[idx]

    idx = np.where(precision > 0.5)[0].min()
    R.smallest_precision_greater_than_50pct = precision[idx]
    R.recall_at_precision_50pct = recall[idx]
    R.threshold_at_precision_50pct = thresholds[idx]

    R = R.__dict__
    R.update(kwargs)
    return R </code></pre>
</details>

<details>
      <summary> Boilerplate for configuring logger in python </summary>
      <pre><code> import logging
def setup_logger(file_path=None):
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
    )

    if all(not isinstance(e, logging.FileHandler)
           for e in logger.handlers):
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        ch.setFormatter(formatter)
        logger.addHandler(ch)
        logger.info(f"Initialized logger with StreamHandler")

    if file_path and all(not isinstance(e, logging.FileHandler)
                         for e in logger.handlers):
        fh = logging.FileHandler(file_path, 'a')
        fh.setLevel(logging.INFO)
        fh.setFormatter(formatter)
        logger.addHandler(fh)
        logger.info(f"Initialized logger with FileHandler({file_path})")

    return </code></pre>
</details>

<details>
      <summary> Java - Python/Numpy Fast Copy-Free Exchange </summary>
      <pre><code> /* Java */

        short a = 3; // 2
        long b = 5; // 8
        float c = (float)7.0; // 4
        ByteBuffer bb = ByteBuffer.allocate(14);
        bb.order(ByteOrder.LITTLE_ENDIAN);
        bb.putShort(a);
        pp(bb.position()); // 2
        bb.putLong(b);
        pp(bb.position()); // 10
        bb.putFloat(c);
        pp(bb.position()); // 14
        bb.position(0); // crucial.
        try(RandomAccessFile f = new RandomAccessFile("/tmp/tmp.dat", "rw");
            FileChannel fc = (f).getChannel();) {
                pp(bb.order().toString());
                pp(fc.write(bb));
        }


        ## Python

        from mmap import mmap, PROT_READ
        import os
        import numpy as np
        import sys
        assert sys.byteorder == 'little'
        fd = os.open('/tmp/tmp.dat', os.O_RDONLY)
        buf = mmap(fd, 14, prot=PROT_READ)
        # L = little endian.
        arr1 = np.frombuffer(buf, dtype=np.dtype('int16').newbyteorder('L'), count=1, offset=0)
        arr2 = np.frombuffer(buf, dtype=np.dtype('int64').newbyteorder('L'), count=1, offset=2)
        arr3 = np.frombuffer(buf, dtype=np.dtype('float32').newbyteorder('L'), count=1, offset=10)
        arr1, arr2, arr3 </code></pre>
</details>

<details>
      <summary> Java - Simple printing function. </summary>
      <pre><code> static void pp(Object format, Object... args) {
        System.out.printf(format.toString(), args);
        System.out.println();
    } </code></pre>
</details>

<details>
      <summary> Json encode numpy objects </summary>
      <pre><code> class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif type(obj).__module__ == 'numpy':
            if type(obj).__name__.startswith('float'):
                return float(obj)
            elif type(obj).__name__.startswith('int'):
                return int(obj)
            else:
                return bool(obj)
        return json.JSONEncoder.default(self, obj) </code></pre>
</details>

<details>
      <summary> List busy EMR machines and the total reserved machines </summary>
      <pre><code> aws emr list-clusters --region us-east-1 --active  > /tmp/tmp1
jq '.Clusters|.[]|.Id' /tmp/tmp1 -r | xargs -n 1 -I % sh -c 'aws emr list-instances --cluster-id % --instance-states RUNNING --region us-east-1' > /tmp/tmp2
jq '.Instances | .[] | .InstanceType' /tmp/tmp2 -r | sort | uniq -c
aws ec2 describe-reserved-instances --region us-east-1 | jq '.ReservedInstances | .[] | [.InstanceType, .InstanceCount, .State]' -c -r | fgrep -v retired | sort </code></pre>
</details>

<details>
      <summary> Excel VBA functions for testing significance of binomial A/B tests. Two-sided ZTest Pvalue from ratios and counts </summary>
      <pre><code> 'Two-sided ZTest Pvalue from counts
Public Function CountsZTest(count1, nob1, count2, nob2)
    CountsZTest = RatioZTest(count1 * 1# / nob1, nob1, count2 * 1# / nob2, nob2)
End Function
Public Function RatioZTest(p1, nob1, p2, nob2)
    diff = p1 - p2
    p_pooled = (p1 * nob1 + p2 * nob2) * 1# / (nob1 + nob2)
    nobs_2xhm = 1# / nob1 + 1# / nob2
    var1 = p_pooled * (1 - p_pooled) * nobs_2xhm
    std_diff = Sqr(var1)
    RatioZTest = Application.WorksheetFunction.Norm_S_Dist(-Abs(diff / std_diff), True) * 2
End Function </code></pre>
</details>

<!-- <details>
      <summary> XXX </summary>
      <pre><code> YYYY </code></pre>
</details>
 -->


<h2>Technical Notes</h2>
<table>
  <tbody>
   <tr><td><details>
      <summary>Steps for adding a note</summary>
      <p>Upload a PDF, say note5.pdf to res folder. Clone res/test.html and search-replace any mention of note1.pdf from the html. Finally, link that html file here.
	<!-- <tr><td> <a href="res/XXXX.html">NOTE XXXX</a>XXXX.</td></tr> -->
      </p>
   </details></td> </tr>
   <tr><td> <a href="res/exploration-scavenging.html">Note 10</a> Exploration Scavenging in comparison to other off-policy estimators. </td></tr>
   <tr><td> <a href="https://www.youtube.com/watch?v=pKuVUmpYkLk">Note 9</a> Using a PID Controller for controlling the number of servers in a data-center.<a href="https://news.ycombinator.com/item?id=27732236">[YC]</a><a href="https://gist.github.com/pushpendre/359706010c20bc1d18123510749f5da5">[Gist]</a></td></tr>
   <tr><td> <a href="res/bankroll_kelly.html">Note 8</a> Using kelly criterion for bankroll management. </td></tr>
   <tr><td> <a href="res/mvue-foundations.html">Note 7</a> The foundations for finding MVUE via the use of Rao-Blackwellization.</td></tr>
   <tr><td> <a href="res/the-vw-faq.html">Note 6</a> The VW FAQ.</td></tr>
   <tr><td> <a href="/ViewerJS/?zoom=page-width#../res/the-basics-of-zeromq.pdf">Note 5</a> The Basics of ZeroMQ.</td></tr>
   <tr><td> <a href="res/graphical_summary_of_elements_of_information_theory.html">Note 4</a> A visual summary of the inequalities govening Entropy, Cross Entropy, Joint Entropy, KL Divergence, and Mutual Information including the Data Processing Inequality.</td></tr>
    <tr><td> <a href="res/note3.pdf">Note 3</a> [WIP] A visual proof of the UCB algorithm. </td></tr>
    <tr><td> <a href="res/note2.mp4">Note 2</a> A video tutorial about the difference between PnL and Cashflow, and how a company can have positive cash flow but still make loss, without raising debt. (you may need to download the video and play with VLC)</td></tr>
    <tr><td>
          <a href="res/note1.html">Note 1</a>: Describes how the variance of an AB test can be reduced in the special case when we are comparing two policies with the same small-finite action space.
          <details>
            <summary>हिंदी विवरण</summary>
            <p>हम दो विधियों/treatments के बीच में कितना फर्क है ये पता करना चाहते है। साधारण तरीका होगा AB testing/ randomized control trials जिसमें की हम randomly/बेतरतीब तरिके से आधे लोगो को विधि A आवंटित करते है और आधे को विधि B प्रदान करते है । उसके बाद दोनों दल में औसत फर्क का अंतर हम पता करते है । ये सबसे आसान पद्धति हैं  और   मानलो की इस पद्धति को इस्तेमाल करने पर हमे 10000 लोगो पे परीक्षण करना पड़ेगा ताकि हम 10% का फर्क दोनो दलों के बीच मे पता कर पाए। जो pdf मैंने भेजी है वो एक विशेष स्थिति का विश्लेषण प्रशेष करती है जो की 25%  कम sample इस्तेमाल करती है। ofcourse ये कोई नई तकनीक नही है सिर्फ मैने अपनी समझ के लिये लिखी है।</p>
          </details>
        </td>
    </tr>

  </tbody>
</table>

<h2>Trivia</h2>
<!-- <details><summary></summary></details> -->

<details><summary>how to add trivia</summary>
      <p>First compile a pdf, either in overleaf, or using latexmk, then add all the assets, the .tex and .pdf file to res/trivia folder.
      Then add the iframe with src, loading, width, height attributes.</p>
</details>

<details><summary>Basics of Hamiltonian Dynamics</summary>
<p>
Based on <a href="https://wiki.math.ntnu.no/_media/aarms2015/lectures/volumepreservation.pdf">link</a>&nbsp;and <a href="http://www.mcmchandbook.net/HandbookChapter5.pdf">link</a>.&nbsp;</p>

<p>Hamiltonian dynamics operate on momentum, position vectors <span class="math-tex">\( p \in \mathbb{R}^d \text{ and } q \in \mathbb{R}^d \)</span>. The system is described by a function <span class="math-tex">\( H(p, q) \)</span> called the Hamiltonian function. This function obeys certain differential equations that arise due to symmetries and conservation laws. These differential equations are</p>

<p style="text-align:center"><span class="math-tex">\[ \begin{align}\frac{dq}{dt} &amp;= \frac{\partial H}{\partial p}&amp;= \text{velocity} \\ \frac{dp}{dt} &amp;= - \frac{\partial H}{\partial q} &amp;\approx \text{force} \end{align} \]</span></p>

<p>Note that these differential equations automatically mean that the hamiltonian function is <strong><span style="color:#169179">conserved/constant</span></strong> w.r.t. time because</p>

<p style="text-align:center"><span class="math-tex">\[ \frac{dH}{dt} = \frac{\partial H}{\partial p} \frac{dp}{dt} + \frac{\partial H}{\partial q}\frac{dq}{dt} = \frac{dq}{dt} \frac{dp}{dt} - \frac{dp}{dt}\frac{dq}{dt} = 0 \]</span></p>

<p>Also the hamiltonian is <strong><span style="color:#169179">reversible</span></strong> in time, simply by negating the time-derivative. Often we can write this hamiltonian as <strong>the sum</strong> of the kinetic plus the potential energy, i.e. <span class="math-tex">\[ H = \text{Potential}, U(q) + \text{Kinetic}, K(p) \]</span>Note that &quot;position&quot; and &quot;momentum&quot; can be replaced by made up quantities, they are &quot;formal variables&quot; of the system. E.g. when doing hamiltonian monte carlo the system is &quot;formalized&quot; as &quot;q&quot; (the position) being the random variable that we want to sample, and &quot;p&quot; being the mean-zero non-standard variance gaussian that we can sample.&nbsp;</p>

<p><span style="color:#169179"><strong>Liouville&#39;s theorem of volume preservation for hamiltonian systems.</strong></span></p>

<p>If we forward-execute the differential equations for a set of points in some region R of (q,p) space that has volume V, then the volume of the the image of R will also be V.&nbsp; This can be proven either by showing that the divergence of this vector field is zero (see theorem below), or by directly showing that the determinant of the jacobian matrix of the instantaneous mapping is 1 at arbitrary time t.&nbsp;</p>

<p style="text-align:center"><span class="math-tex">\(\displaystyle \text{det}\Big(\text{jac}\big((q(t), p(t)) \to (q(t+\delta), p(t+\delta))\big)\Big) = 1\)</span></p>

<p>The instantaneous mapping can be approximated as&nbsp;</p>

<p style="text-align:center"><span class="math-tex">\(T_{\delta}(q,p) = \begin{bmatrix}q \\ p \end{bmatrix} + \delta \begin{bmatrix}dq/dt \\ dp/dt\end{bmatrix} = \begin{bmatrix}q \\ p \end{bmatrix} + \delta \begin{bmatrix}\partial H/\partial p \\ \partial H/\partial q\end{bmatrix}\)</span></p>

<p>and therefore its jacobian can be written as an identity matrix (from the first [q,p] term) plus the matrix of second order partial derivatives, i.e.</p>

<p style="text-align:center"><span class="math-tex">\(B_\delta = \text{jac}(T_{\delta}) = \begin{bmatrix}
1 + \delta \frac{\partial^2H}{\partial q_j \partial p_i} 
&amp;  \delta \frac{\partial^2H}{\partial p_j \partial p_i}
\\
-\delta  \frac{\partial^2H}{\partial q_j \partial q_i}
&amp; 1 -\delta \frac{\partial^2H}{\partial p_j \partial q_i}
\end{bmatrix}\)</span>&nbsp;</p>

<p>&nbsp;</p>

<table align="left" border="2" cellpadding="2" cellspacing="2">
	<thead>
		<tr>
			<th scope="col"><span style="color:#8e44ad"><strong>Theorem : All divergence free systems preserve volume.</strong></span></th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>
			<p>Let <span class="math-tex">\(D \text{ be an open and bounded subset of } \mathbb{R}^d \text{ and let }\dot{y} = f(y) \)</span>&nbsp;be a system of differential equations. The function that maps D to its image at time t is called the flow. Let&nbsp;<span class="math-tex">\(\varphi_t\)</span>&nbsp;be the flow, i.e.&nbsp;<span class="math-tex">\(D(t) = \varphi_t(D)\)</span>&nbsp; and&nbsp;<span class="math-tex">\(\text{vol}(D(t)) = \int_{D(t)} dV\)</span>. . The divergence of the gradient-vector-field&nbsp;is defined as&nbsp;<span class="math-tex">\(\displaystyle \sum_i \frac{\partial \dot{y}_i}{\partial y_i}\)</span>and this is a vector-field itself. If this divergence-verctor-field is 0 for all time then&nbsp;<span class="math-tex">\(\text{vol}(D(t)) = \text{vol}(D)\)</span>. This proof primarily relies on three facts.&nbsp;</p>

			<ol>
				<li>The divergence of a gradient-vector-field is the trace of the jacobian of the time-derivative-vector-field.</li>
				<li><span class="math-tex">\(\text{det}(I + \epsilon A) = 1 + \epsilon\ \text{trace}(A) + \mathscr{O}(\epsilon^2)\)</span></li>
				<li><span class="math-tex">\(\text{vol}(D(t)) \triangleq \displaystyle \int \text{det}\Big(\frac{\partial \varphi_t}{\partial y}\big) dV\)</span>&nbsp;and&nbsp;<span class="math-tex">\(\varphi_t(y) \triangleq y + t f(y) + \mathscr{O}(t^2)\)</span></li>
			</ol>

			<p>In terms of the physical intuition the divergence is kind of the instantaneous change in the strength of a vector-field&nbsp;wrt to the phase-space.</p>
			</td>
		</tr>
	</tbody>
</table>

<p><br />
<span style="color:#169179"><strong>Symplecticness of the jacobian of the hamiltonian</strong></span></p>

<p>Weyl came up with the word &quot;symplectic&quot; as a substitute for the word &quot;complex&quot;. When a system of differential equations is symplectic then that means that the jacobian matrix is a symplectic matrix, and a symplectic matrix has a type of &quot;weird&quot; skew-symmetric &quot;similarity&quot; structure.&nbsp;A symplectic matrix is a <span class="math-tex">\(2n \times 2n\)</span>&nbsp;matrix with real entries that satisfies the condition&nbsp;<span class="math-tex">\( M^T \Omega M = \Omega \)</span>&nbsp;where&nbsp;<span class="math-tex">\(\Omega\)</span>&nbsp;is a fixed nonsingular, skew-symmetric matrix. Symplectic matrices are nonsingular, they have determinant +1 and their inverse matrix can be easily found as&nbsp;<span class="math-tex">\(M^{-1} = \Omega^{-1} M^T \Omega\)</span>. They form a subgroup of the general linear group under matrix multiplication. Volume preservation under a linear operator is naturally implied by symplecticness.</p>

<p>The time evolution of Hamilton&#39;s equations is a &quot;symplectomorphism&quot; because it conserved the symplectic 2-form. A 2-form is a function that measures oriented areas. A numerical scheme for the discretization of a differential equation is a symplectic integrator if it also conserves this 2-form. Most of the usual numerical methods like the Euler scheme and the Runge-Kutta scheme are&nbsp;<u>not symplectic</u>&nbsp;therefore other methods like the leap-frog method are needed. Remember that when we are doing numerical integration then the whole game is in coming up with the right sequence of discrete which will not produce compounding errors.</p>

<p><span style="color:#16a085"><u><strong>For example</strong></u></span>, consider this example where the position and momentum are both 1-dim values and the kinetic energy is momentum-squared and potential energy is position-squared. Then&nbsp;</p>

<p style="text-align:center">&nbsp;<span class="math-tex">\[ \frac{dq}{dt} = p, \text{ and } \frac{dp}{dt} = -q \implies \frac{d^2p}{d^2t} = -p \]</span>&nbsp;</p>

<p>which means that p is a sinusoidal function. Now if we try to do numerical integration of this system of differential equations by the following scheme called the euler-scheme</p>

<p style="text-align:center">&nbsp;&nbsp;<span class="math-tex">\[ \begin{align} p(t+\epsilon) := p(t) + \epsilon \dot{p} (t) = p(t) - \epsilon q(t)\\ q(t+\epsilon) = q(t) + \epsilon \dot{q}(t) = q(t) + \epsilon p(t) \end{align} \]</span>&nbsp;</p>

<p>then we can see that this discretization is non-symplectic because the matrix looks like this <span class="math-tex">\( \begin{bmatrix}1 &amp; -\epsilon \\ \epsilon &amp; 1 \end{bmatrix} \)</span>which has determinant <span class="math-tex">\( 1 + \epsilon^2 \)</span> otoh if we do discretization in this manner</p>

<p style="text-align:center"><span class="math-tex">\[ \begin{align} p(t+\epsilon) &amp;:= p(t) + \epsilon \dot{p} (t) &amp;&amp;= p(t) - \epsilon q(t)\\ q(t+\epsilon) &amp;= q(t) + \epsilon \dot{q}(t+\epsilon) &amp;&amp;= q(t) + \epsilon p(t+\epsilon) \end{align} \]</span></p>

<p>then the transformation is <span class="math-tex">\( \begin{bmatrix}1 &amp; -\epsilon \\ \epsilon &amp; 1-\epsilon^2\end{bmatrix} \)</span> which has determinant 1 !! So this simple &quot;gibbs-sampling&quot; style sequential update does wonders. <strong><span style="color:#169179">The leapfrog method</span></strong> is even better for integrating symplectic systems because it works as follows, first do a half-update to momentum, then a full update to position, and then the remaining half update to momentum.&nbsp;</p>
	    
</details>

<details><summary>High Contrast ML</summary>
<p><strong>High Contrast ML</strong></p>
<p>&nbsp;</p>
<p>The word contrast comes up a lot in ML. Specifically, there are</p>
<ol>
<li>Contrastive Loss - This loss is kind of like a siamese loss, the within-class embeddings should be close (geometrically) and the between-class embeddings should be far apart. Specifically this method minimized L2-distance between embeddings from same-class and laterally-inverted squared-hinge-loss for embeddings between classes.<br><br></li>
<li>Triplet Loss and other generalization - Triplet loss simply tries to contrast pairs of pairs. So there is a desirable pair and an undesirable pair. This just generalizes the idea of class-label-based equivalence classes to just directly classifying pairs of examples.<br><br></li>
<li>Noise Contrastive Estimation - This is used for density estimation in special types of energy-based-models called the log-linear models where the gradient of the log-likelihood of a sample equals the sample-features minus the expected value of the features under the model's own distribution. The basic idea is to draw negative samples from some kind of a proposal distribution , make one assumption that the partition function is 1, and then do energy based modeling.</li>
<li>Negative Sampling - Make the score of the data higher and make the score of the noise-words lower in the context of the current word.<br><br></li>
<li>SimCLR - See below.<br><br></li>
<li>Contrastive Estimation by Smith and Eisner - Come up with perturbations that destroy meaning so much that it's better to treat them as negative examples.</li>
</ol>
<p><em><span style="text-decoration: underline;">Generalized contrast and agreement</span></em></p>
<p>In general there can be two types of perturbations, once which preserve meaning/semantics, e.g. small guassian noise in images, adding small patches, cropping, translation, and ones which destory all meaning, such as sampling from a completely different distribution called the noise distribution, extreme permutation of pixels, replacing with instances from a different class.&nbsp;Within NLP it is easy to come up with meaning-destroying perturbation such as permutation, replacement by different noisy sentence,&nbsp; however it is a lot harder to come up with a meaning preserving perturbation, one way would be back-translation, another way will be replacing certain words by their synonyms, or by "visual back-translation"</p>
<p>Good methods use both types of perturbations, e.g. the SimCLR method maximizes agreement between the representations of meaning preserving perturbations and it minimizes agreement between representations of random unrelated data-samples.</p>
<p>&nbsp;</p>
	</details>
<details><summary>Lessons from the Open Pre-Trained Transformer Logbook</summary>
	<p>Lessons from the metaseq <a href="https://arxiv.org/abs/2205.01068">paper</a> and the "Open Pre-Trained Transformer" <a href="https://github.com/facebookresearch/metaseq/tree/main/projects/OPT">project</a>. There is another paper by DeepMind called <a href="https://arxiv.org/pdf/2112.11446.pdf">Gopher</a> that I haven't read. The large scale OPT-175B model was trained on 1000, 80GB, A100 GPUs for around 34-35 days on around 180B tokens ≅ 800GB of text data. Each A100 offers 312 Teraflops and the meta system reached 147 Tflops utilization. The state of the optimizer "AdamW" is stored in FP32 format, whereas the model weights are stored in FP16 format. The different floating points have the following format.</p>
<table style="border-collapse: collapse; width: 99.9844%;" border="1">
<tbody>
<tr>
<td style="width: 48.0624%;">Format</td>
<td style="width: 48.0624%;">(Sign=1, Range/Exponent, Precision/Mantissa)</td>
</tr>
<tr>
<td style="width: 48.0624%;">FP32</td>
<td style="width: 48.0624%;">8, 23</td>
</tr>
<tr>
<td style="width: 48.0624%;">TF32</td>
<td style="width: 48.0624%;">8, 10</td>
</tr>
<tr>
<td style="width: 48.0624%;">FP16</td>
<td style="width: 48.0624%;">5, 10</td>
</tr>
<tr>
<td style="width: 48.0624%;">BF16</td>
<td style="width: 48.0624%;">8, 7</td>
</tr>
</tbody>
</table>
<p>So the total training floating point ops were about 0.4Yotta operations. At inference time, the entire process can be sped up by 30-50% by investing in sparsifying with 2:4 sparsity.</p>
<details>
<summary>how to generate a structured sparse network using APEX's Automatic Sparsity library</summary>
<pre class="language-python"><code>""" Generate a structured sparse network using APEX's Automatic Sparsity library.
"""
import torch
from apex.contrib.sparsity import ASP
device = torch.device('cuda')
model = TheModelClass()
model.load_state_dict(torch.load("dense_model.pth")) # Load existing model
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
ASP.prune_trained_model(model, optimizer)
dataloader = DataLoader()
for t in range(500):
      optimizer.zero_grad()
      loss = loss_fn(model(x), y)
      loss.backward()
      optimizer.step()

torch.save(model.state_dict(), "pruned_model.pth")</code></pre>
</details>
<p>The batch size was 0.5M-4M and each sequence length was 2048. The total model size was 350GB and assuming that a checkpoint was made after every 1hr of work will mean that 264TB of disk space was required just to store the checkpoints. One of the cheapest cloud provider for A100 is lambdalabs that charges $1.1/hr/A100gpu so the training cost will be $892K. OTOH the acquisition cost for 1000 A100 is 11K$ * 1000 = 11M$. If one acquires 100 3090 or 3080 for personal/commercial use then <a href="https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86">the cost can come down to 100K$</a> and the electricity-cost to run A100s which take something between 300W to 1KW will be 7.26e-2$/KW/H * 24 * 1 * 33 * 1024 = 59K$ which is 1/20th of the cloud-rent. But the 3090/3080 have smaller memory at 24/12GB instead of the 80/40GB for A100.&nbsp;</p>
<p>In terms of algorithmic decisions the main things to decide while training large LMs are following:</p>
<table style="border-collapse: collapse; width: 99.9844%;" border="1">
<tbody>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;"><strong>Decision Dimensions</strong></td>
<td style="width: 50.068%;"><strong>Specific to MetaSeq (OPT)</strong></td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Activation Function</td>
<td style="width: 50.068%;">Relu (they weren't able to get swish to work well with Mixed Precision)</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Seq. Length</td>
<td style="width: 50.068%;">2048</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Optimizer</td>
<td style="width: 50.068%;">AdamW (see below)</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">LR Scheduler</td>
<td style="width: 50.068%;">Triangular (Howard and Ruder from FastAI)</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Batch Size</td>
<td style="width: 50.068%;">0.5 - 4M</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Gradient Clipping</td>
<td style="width: 50.068%;">&nbsp;</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Dropout</td>
<td style="width: 50.068%;">0.1</td>
</tr>
<tr>
<td style="width: 10.2519%;">&nbsp;</td>
<td style="width: 39.6797%;">Dynamic Loss Scaling</td>
<td style="width: 50.068%;">&nbsp;</td>
</tr>
</tbody>
</table>
<p><strong>AdamW : </strong>Broadly speaking the decoupled weight decay idea is that instead of computing the momentum from the regularized loss, we compute momentum from the unregularized loss but then regularize the weight update. This was described on <a href="https://arxiv.org/pdf/1711.05101.pdf">page 3 of this paper.</a></p>
<p><strong>Loss Scaling :&nbsp;</strong>The FP16 numbers can represent exponents ranging from -14 to 15. But usually the gradient values tend to be small in magnitude and therefore they only require negative exponents. If we scale up the loss value before backprogation, then scale back down the values (by using a small learning rate ??) before weight update/gradient clipping or any other gradient-related computations take place.</p>
<p><strong>Timelines :&nbsp;</strong>GPT3 details were released on May 2020, FB OPT was trained around Dec 2021, and Gopher model details were released in Dec 2021. The FB team was using Azure cloud provider.</p>
<p><strong>Automatic Mixed Precision</strong> <strong>via <a href="https://github.com/NVIDIA/apex">NVIDIA APEX</a> and <a href="https://developer.nvidia.com/blog/apex-pytorch-easy-mixed-precision-training/">AMP</a></strong> :&nbsp;</p>
<pre class="language-python"><code># At the logical level, Amp works by employing a whitelist / blacklist model.
# We divide the universe of functions into three sets:
# Whitelist : Functions where we expect a speedup with FP16 math.
# Blacklist : Functions for which 16 bits of precision may not be sufficient. 
#     so we want to ensure that inputs are in FP32, the most common examples 
#     of these are the neural net loss functions like softmax with cross entropy.
# Everything : Treated like blacklist.

from apex import amp
model, optimizer = amp.initialize(model, optimizer)
loss = criterion(…)
with amp.scale_loss(loss, optimizer) as scaled_loss:
    scaled_loss.backward()
optimizer.step()</code></pre>
<p><strong>Systems Stuff</strong></p>
<p>A useful Linux Commands is <code>pdsh</code> which can do remote execution via ssh on multiple machine.&nbsp;</p>
<p><strong>Nvidia Networking Glossary</strong></p>
<ul>
<li>NVIDIA NVLink enables high-speed peer-to-peer communication between GPUs within a node.</li>
<li>Nvidia Infiniband and Ethernet support upto 200GB/s data speed for inter-node GPU comm. Infiniband is better because it has much lower latency so it can transfer "medium" sized packets quicker.</li>
<li>RDMA -- This is naturally supported on Infiniband and is available via ROCE (RDMA over converged ethernet).&nbsp;</li>
<li>NCCL -- NVIDIA collective communication library.</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</details>
<details><summary>The optimization landscape</summary>
<p><strong>The optimization landscape </strong></p>
<p>(<a href="https://math.stackexchange.com/questions/486400/help-me-organize-these-concepts-kkt-conditions-and-dual-problem" target="_blank" rel="noopener">another person's attempt</a>, <a href="https://fmin.xyz/" target="_blank" rel="noopener">another attempt</a>)</p>
<p>There are two kinds of optimization problems, unconstrained and constrained. Both of these two types of problems have their own conditions for optimality, the conditions for optimality may be first order or second order and they may be necessary or sufficient. These get further subdivided into differentiable or nondifferentiable objective. Further subdivision is possible on the basis of whether the equality/inequality constraints are linear or affine or quadratic or conic etc.&nbsp;</p>
<table style="border-collapse: collapse; width: 99.9981%;" border="1">
<tbody>
<tr>
<td style="width: 48.7089%;">
<p>Differentiable (convex or otherwise)</p>
<ul>
<li>Unconstrained
<ul>
<li>First order - gradient is zero</li>
<li>Second order - hessian is positive definite</li>
</ul>
</li>
<li>Constrained<br>
<ul>
<li>First Order - linear independent active constraint (qualification) + KKT <em>( lagrangian's grad = 0, feasibility, complementarity)</em></li>
<li>Second Order -&nbsp;</li>
</ul>
</li>
</ul>
</td>
<td style="width: 48.7089%;">
<p>Nondifferentiable / Convex</p>
<ul>
<li>&nbsp;Unconstrained
<ul>
<li>First order - subdifferential contains 0.</li>
<li>Second order -&nbsp;</li>
</ul>
</li>
<li>Constrained
<ul>
<li>First Order -&nbsp;</li>
<li>Second Order&nbsp;</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Now we can have a number of convex optimization algorithms, and these algorithms may either produce a good iterate at any point during the iteration, or at the last iterate.</p>
<ol>
<li>Steepest descent - Keep picking the smallest norm subgradient, which we can find by projecting 0 onto the subdifferential, and then line searching. This has the nice effect that we make guaranteed progress at every step.</li>
<li>Follow any subgradient - Unfortunately this wont be a descent algorithm. But we are provably going to get closer to the true solution in parameter space !</li>
<li>Projected subgradient method for constrained optimization -&nbsp;</li>
<li>Cutting plane methods - keep making a better and better linear model of the true optimization problem. The key observation is that minimizing the maxima of multiple LPs is also an LP. Solving the maxima of LPs is called the master problem.
<ol>
<li>Bundle method - Instead of solving the master problem, solve a regularized master-subproblem that adds a regularization to keep the new iterate close to the old one.</li>
<li>Trust region method</li>
</ol>
</li>
</ol>
<p><strong>Basic properties of the subgradient, subdifferential, and directional derivative</strong></p>
<ol>
<li>Directional derivatives are one-sided limits (not two-sided). Directional derivatives always exist for convex functions.</li>
<li>Subgradient is a <span style="text-decoration: underline;">linear-underestimator</span> of a convex function. <strong>Note</strong> that both the direction as well as the norm of the subgradient matters.&nbsp;</li>
<li>Subdifferential are closed-convex sets. We get a new subdifferential at each point, and if a point is in the interior of the domain of a convex function then the corresponding subdifferential is&nbsp;<strong>compact! </strong>which means it cannot be a cone! Also shrinking a subgradient by multiplying with a small scalar and then taking a step may not help, because a shrunk-vector may not lie in the subdifferential because 0 may not be in the subdifferential.</li>
<li>The directional-derivative in direction <span class="math-tex">\( d \)</span> is lower bounded by <span class="math-tex">\( \sup_{g \in \partial f(x)} g^T d \)</span> and the steepest descent direction is the one that minimizes the directional derivative which is negative of the minimum norm element of the subdifferential.</li>
</ol>
<p>&nbsp;</p>
</details>
<details><summary>The distribution of many-to-one functions of random variables</summary>
<p>The formula for change of distribution under one-to-one differentiable maps is well-known. If <span class="math-tex">\( f \)</span> maps <span class="math-tex">\( x \)</span> to <span class="math-tex">\( y \)</span> then <span class="math-tex">\( p_Y(y) = p_X(f^{-1}(y)) abs(det( jac_{f^{-1}}( y )) \)</span>. However what happens in the more general case where let's say that the function is not invertible ? This can happen in situations like Z = X/Y or Z = X + Y etc. In such situations the most clean method is to compute the probability of the event underlying the CDF and then differentiating. Basically</p>
<p><span class="math-tex">\[ \begin{align}p_Z(z) &amp;= \frac{d}{dz} \int_{\mathbf{x}} \mathbb{I}[f(\mathbf{x}) &lt; z] \ p_{\mathbf{X}}(\mathbf{x}) d\mathbf{x} = \frac{d}{dz} \int_{\mathbb{I}[f(\mathbf{x}) &lt; z]}  \ p_{\mathbf{X}}(\mathbf{x}) d\mathbf{x}
\end{align} \]</span></p>
<p>Now recall that <span class="math-tex">\( \frac{d}{dx}\int_a^{u(x)} f(t) dt = u'(x) f(u(x)) \)</span> therefore if we can write the acceptable region as a function of <span class="math-tex">\( z \)</span> then we are in business. For example, if <span class="math-tex">\( z = x_2/x_1 \)</span> then the acceptable region is <span class="math-tex">\( \{x_1 &gt; 0, x_2 &lt; zx_1\} \cup \{x_1 &lt; 0, x_2 &gt; zx_1\} \)</span> and the integral is <span class="math-tex">\[ \int_0^\infty x_1 p(x_1, zx_1)dx_1 + \int_{-\infty}^0-x_1p(x_1, zx_1)dx_1 \]</span>where the derivative has been interchanged assuming fubini's theorem applies in this case.</p>
</details>
<details><summary>Calculus Theorems</summary>
<ul>
<li>MVT - a continuous and differentiable function has atleast one point between a, b that achieves the linear slope between these two points.</li>
<li>EVT - continuos functions on compact sets achieve extrema.</li>
<li>Intermediate Value T - If f is a continuous function then the image of an interval is also an interval.</li>
<li>Taylor's Expansion - This is the best polynomial approximation <span class="math-tex">\( f(x) = f(a) + f'(a)(x - a) + \frac{f''(a)}{2!} (x - a)^2 + ... h_k(x) (x - a)^k \)</span>with <span class="math-tex">\( \lim_{x \to a}h(x) = 0 \)</span> for analytic functions. Taylor's theorem also has a multivariate version.</li>
<li>Newton's method for root of f(x) = x - f(x)/f'(x) derived by taylor expansion. Newton's method for optimization therefore involves the inverse of the derivative of the gradient, i.e. the inverse of hessian.</li>
<li>Darboux's theorem - Every function that has an integral, i.e. this function resulted from the differentiation of another function, satisfied the IVT property even if it not continuous. See this page for example of a function with <a href="https://calculus.subwiki.org/wiki/Derivative_of_differentiable_function_need_not_be_continuous">non-continuous derivative&nbsp;</a> and see this page <a href="https://math.stackexchange.com/questions/292275/discontinuous-derivative">for more exotic function</a></li>
<li>Clairaut's theorem for symmetry of second derivatives , i.e. <span style="text-decoration: underline; color: #b96ad9;">when can we interchange differentiation</span> ? The second partial derivatives need to exist and be continuous.&nbsp;</li>
<li>Fubini's theorem, i.e. <span style="text-decoration: underline; color: #b96ad9;">when can we interchange integration</span> ? absolute integrability implies interchange is possible.</li>
<li>Leibniz Integral rule, i.e. <span style="text-decoration: underline;"><span style="color: #e67e23; text-decoration: underline;">when can we interchange differentiation and integration</span></span> ? Let <span class="math-tex">\( f(x,t) \)</span> be a function such that both f and its partial derivative <span class="math-tex">\( f_x \)</span> are continuous and suppose that the limit functions are continuous and have continuous derivatives. Then&nbsp;<br><span class="math-tex">\[ \frac{d}{dx}\Big(\int_{a(x)}^{b(x)} f(x,t) dt\Big) = f(x,b(x)) b'(x) - f(x,a(x))a'(x) + \int_{a(x)}^{b(x)} \frac{\partial f(x,t)}{\partial x}dt \]</span></li>
<li>Inverse function theorem -- If f is continuously differentiable in nbhd of <span class="math-tex">\( a \)</span> and its derivative is nonzero at <span class="math-tex">\( a \)</span> then the function is invertible and the inverse is continuously differentiable and the derivative is <span class="math-tex">\( 1/f'(f^{-1}(b)) \)</span></li>
<li>Implicit function theorem -- Given a system of m equations <span class="math-tex">\( \{f_i(x_1, \ldots, x_n, y_1, \ldots, y_m) = 0 \mid i=1,\ldots,m\} \)</span> satisfied at point <span class="math-tex">\( (\bar{a},\bar{b}) \)</span> under a mild condition on the partial derivateives with respect to <span class="math-tex">\( y_i \)</span> (that the jacobian of partial derivatives wrt to y is intertible) and the system itself is continuously differentiable in a nbhd of <span class="math-tex">\( (\bar{a},\bar{b}) \)</span> then the y variables are unique continuously differentiable functions of <span class="math-tex">\( \{ x_j \} \)</span> in some nbhd of the point. And infact this theorem also gives the formula for the jacobian of this unique function.</li>
</ul>
</details>
<details><summary>Difference between testing for non-stationarity tests vs testing for trend</summary>
	<p>Stationarity simply means that the n-th order joint pdfs are independent of time. Wide-sense stationarity (or loose sense stationarity) means that the mean is constant with time, and that the correlation between any two observations only varies as a function of time. Stationarity does not mean that the the correlation function (R<sub>X</sub> (T<sub>1</sub>, 𝛕= T<sub>2</sub> - T<sub>1</sub>)) is zero or delta function. No! Wide-Sense Stationarity just means that the correlation function is invariant with time, only depends on the difference. Note that stationarity / non-stationarity describes a process, not the actual observed signal. The observed signals can still exhibit periodicity while being w-stationary. Now In an auto-regressive (AR) process, the current value of the signal is a linear function of past observations plus a noise term. This process can be non-stationary if the system has a so-called "unit-root". but AR processes <strong>may</strong> still be stationary without trend. OTOH Moving average processes (MA) are always defined as linear combinations of observations coming from some hidden iid error terms. So the MA process is <strong>always</strong> stationary. Dickey Fuller procedure tests whether a unit-root it present in an AR process. There are different versions of this test depending on exactly what type of AR process is assumed and even what is the alternative to the null hypothesis such as&nbsp;Augmented Dickey Fuller, KPSS. But none of these tests can check for whether a trend is present in the dataset because these "stationarity" tests can give false-positives for trend. If a *DF test or KPSS test says that the signal is stationary then rest assured we can say that no trend exists, but when these tests say that a trend exists, then it's possible that they are just detecting a unit-root random walk which obviously does not have actual trend.</p>
</details>
<details><summary>Hessian with Backprop.</summary>
      <p><iframe src="/ViewerJS/?zoom=page-width#../res/trivia/hessian-with-backprop.pdf" loading="lazy" width="720" height="400"></iframe></p>
</details>

<details><summary>The delta method.</summary>
      <p><iframe src="/ViewerJS/?zoom=page-width#../res/trivia/the-delta-method.pdf" loading="lazy" width="720" height="400"></iframe></p>
</details>

<details><summary>Variational characterization of the absolute value function.</summary>
      <p><iframe src="/ViewerJS/?zoom=page-width#../res/trivia/variational-characterization-of-absolute-value.pdf" loading="lazy" width="720" height="400"></iframe></p>
</details>

<details><summary>The T distribution and its relation to sampling.</summary>
      <p><iframe src="/ViewerJS/?zoom=page-width#../res/trivia/the-t-distribution.pdf" loading="lazy" width="720" height="400"></iframe></p>
</details>

<h2>Hobby Software/Hardware Projects (Personal)</h2>
<details><summary>FlagPlanter / Timestamper App for deepfake prevention, Evidence Timestamping with working apk</summary>
      <p><a href="https://github.com/pushpendre/flagplant/">The flag planter app help to claim priority over an idea without revealing the idea itself to the world.</a></p>
</details>

<h2>Hobby Software/Hardware Projects (Others)</h2>
<details><summary>Hosted Jsmol: an open-source Javascript viewer for chemical structures in 3D. <a href="https://pushpendre.github.io/res/bio/jsmol/">link.</a></summary>
</details>
<details><summary>Hosted JSME: an open-source Javascript Molecule Editor. <a href="https://pushpendre.github.io/res/bio/jsme/">link.</a></summary>
</details>

<h2>Diary</h2>
<details><summary>Mom</summary>
      <p><a href="res/mom.html">My mom's untimely death.</a></p>
</details>
<details><summary>Dad</summary>
    <p><a href="res/dad.html">How we navigated my father's diagnosis for cardiac ischemia.</a></p>
</details>
</div>
</div>
</body>
</html>
