<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Online Sample Complexity Bound Calculator</title>
  <meta name="description" content="Learning theory provides probabilitic guarantees on the deviation between training error of a certain size and true errors. I don’t think people actually use...">

  <link rel="stylesheet" href="/~prastog3/css/main.css">
  <link rel="canonical" href="/~prastog3/2015/07/28/sample-complexity-bound-calculator.html">
  <link rel="alternate" type="application/rss+xml" title="Pushpendre Rastogi" href="/~prastog3/feed.xml" />
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    TeX: { equationNumbers: { autoNumber: "AMS" },
    Macros : {rs: ["#1", 1],
              rv: ["\\boldsymbol{#1}", 1],
              rm: ["\\boldsymbol{#1}", 1],
              us: ["\\mathsf{#1}", 1],
              uv: ["\\mathbf{#1}", 1],
              um: ["\\mathbf{#1}", 1],
              ks: ["\\mathtt{#1}", 1],
              kv: ["\\mathtt{#1}", 1],
              km: ["\\mathtt{#1}", 1]}}});
  </script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <img class="site-title" src="/~prastog3/res/header.png" height="100" style="PADDING-RIGHT: 10px">
    <a class="site-title" href="/~prastog3/">Pushpendre Rastogi</a>
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
        
          
        
          
        
          
          <a class="page-link" href="/~prastog3/mvlsa/">Multiview LSA</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Online Sample Complexity Bound Calculator</h1>
    <p class="post-meta">Jul 28, 2015</p>
  </header>

  <article class="post-content">
    <p>Learning theory provides probabilitic guarantees on the deviation between training error of a certain size and true errors. I don’t think people actually use these bounds literally, rather these bounds are used to get some sense of trends. For example, the wisdom that the number of samples needed for learning grows linearly with the number of parameters in the model which can be justfied because the sample complexity of ERM increases linearly with the VC dimension <a href="#ng2002discriminative">(Ng &amp; Jordan, 2002)</a> <a href="#shalev2014understanding">(Shalev-Shwartz &amp; Ben-David, 2014)</a></p>

<script type="math/tex; mode=display">m(\delta , \epsilon) = \Theta(\frac{d + \log(\frac{1}{\delta})}{\epsilon^2})</script>

<p>This formula comes with a large number of conditions. This is for 0-1 loss on a binary classification problem for the ERM algorithm in the agnostic setting. In this post I have put up an online script that calculates the sample complexities for some hypothesis spaces. Most useful case perhaps is the setting when “is_validation” is set to 1. This case can basically help us design the number of samples to keep in our dataset for good generalization to the test data. Of course if the test data has a different distribution then these bounds won’t be useful.</p>

<p>####Bibliography####</p>
<ol class="bibliography"><li><span id="ng2002discriminative">Ng, A., &amp; Jordan, I. M. (2002). On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. <i>Advances in NIPS 14</i>.</span></li>
<li><span id="shalev2014understanding">Shalev-Shwartz, S., &amp; Ben-David, S. (2014). <i>Understanding Machine Learning: From Theory to Algorithms</i>. Cambridge University Press.</span></li></ol>

<iframe src="https://trinket.io/embed/python/1719908ef5" width="100%" height="600" frameborder="0" marginwidth="0" marginheight="0" allowfullscreen=""> </iframe>

  </article>
  
</div>

      </div>
    </div>

    <footer class="site-footer">
  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Pushpendre Rastogi</li>
          <li><a href="mailto:pushpendre@gmail.com">pushpendre@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/se4u">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">se4u</span>
            </a>
          </li>
          
        </ul>
      </div>
    </div>
  </div>
</footer>


  </body>

</html>
